{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender system final project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mohamed Amine El Maghraoui\n",
    "\n",
    "SCIA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/46rhbw3d7hs99nwzxbph1zcw0000gn/T/ipykernel_15788/237972807.py:25: DtypeWarning: Columns (15,16,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  orders = pd.read_csv('project_data/orders2.csv')\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Set plot parameters\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 13)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "# Load datasets\n",
    "test_customers = pd.read_csv('project_data/test_customers2.csv')\n",
    "test_locations = pd.read_csv('project_data/test_locations2.csv')\n",
    "train_customers = pd.read_csv('project_data/train_customers2.csv')\n",
    "train_locations = pd.read_csv('project_data/train_locations2.csv')\n",
    "orders = pd.read_csv('project_data/orders2.csv')\n",
    "vendors = pd.read_csv('project_data/vendors2.csv')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Prétraitement des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authentication_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vendor_category_en</th>\n",
       "      <th>vendor_category_id</th>\n",
       "      <th>delivery_charge</th>\n",
       "      <th>serving_distance</th>\n",
       "      <th>is_open</th>\n",
       "      <th>OpeningTime</th>\n",
       "      <th>...</th>\n",
       "      <th>open_close_flags</th>\n",
       "      <th>vendor_tag</th>\n",
       "      <th>vendor_tag_name</th>\n",
       "      <th>one_click_vendor</th>\n",
       "      <th>country_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>device_type</th>\n",
       "      <th>display_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>118597.0</td>\n",
       "      <td>-0.588596</td>\n",
       "      <td>0.754434</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11:00AM-11:30PM</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2,4,5,8,91,22,12,24,16,23</td>\n",
       "      <td>Arabic,Breakfast,Burgers,Desserts,Free Deliver...</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-30 14:42:04</td>\n",
       "      <td>2020-04-07 15:12:43</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>118608.0</td>\n",
       "      <td>-0.471654</td>\n",
       "      <td>0.744470</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>08:30AM-10:30PM</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4,41,51,34,27,15,24,16,28</td>\n",
       "      <td>Breakfast,Cakes,Crepes,Italian,Pasta,Pizzas,Sa...</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-05-03 12:32:06</td>\n",
       "      <td>2020-04-05 20:46:03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>118616.0</td>\n",
       "      <td>-0.407527</td>\n",
       "      <td>0.643681</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>08:00AM-10:45PM</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4,8,91,10</td>\n",
       "      <td>Breakfast,Desserts,Free Delivery,Indian</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-05-04 22:28:22</td>\n",
       "      <td>2020-04-07 16:35:55</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>118619.0</td>\n",
       "      <td>-0.585385</td>\n",
       "      <td>0.753811</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10:59AM-10:30PM</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5,8,30,24</td>\n",
       "      <td>Burgers,Desserts,Fries,Salads</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-05-06 19:20:48</td>\n",
       "      <td>2020-04-02 00:56:17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>118624.0</td>\n",
       "      <td>0.480602</td>\n",
       "      <td>0.552850</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11:00AM-11:45PM</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Burgers</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-05-17 22:12:38</td>\n",
       "      <td>2020-04-05 15:57:41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  authentication_id  latitude  longitude vendor_category_en  \\\n",
       "0   4           118597.0 -0.588596   0.754434        Restaurants   \n",
       "1  13           118608.0 -0.471654   0.744470        Restaurants   \n",
       "2  20           118616.0 -0.407527   0.643681        Restaurants   \n",
       "3  23           118619.0 -0.585385   0.753811        Restaurants   \n",
       "4  28           118624.0  0.480602   0.552850        Restaurants   \n",
       "\n",
       "   vendor_category_id  delivery_charge  serving_distance  is_open  \\\n",
       "0                 2.0              0.0               6.0      1.0   \n",
       "1                 2.0              0.7               5.0      1.0   \n",
       "2                 2.0              0.0               8.0      1.0   \n",
       "3                 2.0              0.0               5.0      1.0   \n",
       "4                 2.0              0.7              15.0      1.0   \n",
       "\n",
       "       OpeningTime  ... open_close_flags                 vendor_tag  \\\n",
       "0  11:00AM-11:30PM  ...              1.0  2,4,5,8,91,22,12,24,16,23   \n",
       "1  08:30AM-10:30PM  ...              1.0  4,41,51,34,27,15,24,16,28   \n",
       "2  08:00AM-10:45PM  ...              1.0                  4,8,91,10   \n",
       "3  10:59AM-10:30PM  ...              1.0                  5,8,30,24   \n",
       "4  11:00AM-11:45PM  ...              1.0                          5   \n",
       "\n",
       "                                     vendor_tag_name one_click_vendor  \\\n",
       "0  Arabic,Breakfast,Burgers,Desserts,Free Deliver...                Y   \n",
       "1  Breakfast,Cakes,Crepes,Italian,Pasta,Pizzas,Sa...                Y   \n",
       "2            Breakfast,Desserts,Free Delivery,Indian                Y   \n",
       "3                      Burgers,Desserts,Fries,Salads                Y   \n",
       "4                                            Burgers                Y   \n",
       "\n",
       "   country_id  city_id           created_at           updated_at device_type  \\\n",
       "0         1.0      1.0  2018-01-30 14:42:04  2020-04-07 15:12:43           3   \n",
       "1         1.0      1.0  2018-05-03 12:32:06  2020-04-05 20:46:03           3   \n",
       "2         1.0      1.0  2018-05-04 22:28:22  2020-04-07 16:35:55           3   \n",
       "3         1.0      1.0  2018-05-06 19:20:48  2020-04-02 00:56:17           3   \n",
       "4         1.0      1.0  2018-05-17 22:12:38  2020-04-05 15:57:41           3   \n",
       "\n",
       "   display_orders  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "orders.drop([ 'promo_code', 'delivery_time', 'order_accepted_time', 'driver_accepted_time', 'ready_for_pickup_time', 'picked_up_time', 'delivered_time', 'delivery_date'], axis=1, inplace=True)\n",
    "\n",
    "# Convert 'is_favorite' and 'is_rated' to binary\n",
    "orders['is_favorite'] = orders['is_favorite'].map({'Yes': 1, 'No': 0})\n",
    "orders['is_rated'] = orders['is_rated'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Fill NaN values in 'is_favorite' and 'is_rated' with 0\n",
    "orders[['is_favorite', 'is_rated']] = orders[['is_favorite', 'is_rated']].fillna(0)\n",
    "\n",
    "# Fill NaN values in 'vendor_rating', 'driver_rating', 'vendor_discount_amount', and 'promo_code_discount_percentage' with 0\n",
    "for col in ['vendor_rating', 'driver_rating', 'deliverydistance', 'preparationtime']:\n",
    "    orders[col].fillna(orders[col].mean(), inplace=True)\n",
    "# Fill NaN values in 'LOCATION_TYPE' with 'Other'\n",
    "orders['LOCATION_TYPE'].fillna('Other', inplace=True)\n",
    "\n",
    "\n",
    "(vendors.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>location_number</th>\n",
       "      <th>location_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02SFNJH</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.682392</td>\n",
       "      <td>-78.789737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02SFNJH</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.679137</td>\n",
       "      <td>0.766823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02SFNJH</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>-0.498648</td>\n",
       "      <td>0.661241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU43CXC</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.100853</td>\n",
       "      <td>0.438165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BDFBPRD</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.523125</td>\n",
       "      <td>0.733464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  location_number location_type  latitude  longitude\n",
       "0     02SFNJH                0         Other  1.682392 -78.789737\n",
       "1     02SFNJH                1         Other  1.679137   0.766823\n",
       "2     02SFNJH                2         Other -0.498648   0.661241\n",
       "3     RU43CXC                0          Home  0.100853   0.438165\n",
       "4     BDFBPRD                0         Other  2.523125   0.733464"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_locations.location_type.fillna('Other', inplace=True)\n",
    "train_locations.latitude.fillna(0, inplace=True)\n",
    "train_locations.longitude.fillna(0, inplace=True)\n",
    "train_locations.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>location_number</th>\n",
       "      <th>location_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z59FTQD</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>126.032278</td>\n",
       "      <td>-9.106019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.278709</td>\n",
       "      <td>-78.623847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.124485</td>\n",
       "      <td>-78.605621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>-0.113891</td>\n",
       "      <td>-78.577449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>-0.848796</td>\n",
       "      <td>0.136726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  location_number location_type    latitude  longitude\n",
       "0     Z59FTQD                0         Other  126.032278  -9.106019\n",
       "1     0JP29SK                0          Home    0.278709 -78.623847\n",
       "2     0JP29SK                1          Home    0.124485 -78.605621\n",
       "3     0JP29SK                2         Other   -0.113891 -78.577449\n",
       "4     0JP29SK                3         Other   -0.848796   0.136726"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_locations.location_type.fillna('Other', inplace=True)\n",
    "test_locations.latitude.fillna(0, inplace=True)\n",
    "test_locations.longitude.fillna(0, inplace=True)\n",
    "test_locations.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vendors.rename(columns={'id': 'vendor_id'}, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Nous construisons ici le dataframe des utilisateurs pour l'algorithme ALS, ici les utilisateurs sont les clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>location_number</th>\n",
       "      <th>location_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02SFNJH</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.682392</td>\n",
       "      <td>-78.789737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02SFNJH</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.679137</td>\n",
       "      <td>0.766823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02SFNJH</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>-0.498648</td>\n",
       "      <td>0.661241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU43CXC</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.100853</td>\n",
       "      <td>0.438165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BDFBPRD</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.523125</td>\n",
       "      <td>0.733464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  location_number location_type  latitude  longitude\n",
       "0     02SFNJH                0         Other  1.682392 -78.789737\n",
       "1     02SFNJH                1         Other  1.679137   0.766823\n",
       "2     02SFNJH                2         Other -0.498648   0.661241\n",
       "3     RU43CXC                0          Home  0.100853   0.438165\n",
       "4     BDFBPRD                0         Other  2.523125   0.733464"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = train_locations\n",
    "users.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et ici nous construisons le même mais pour nos données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>location_number</th>\n",
       "      <th>location_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z59FTQD</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>126.032278</td>\n",
       "      <td>-9.106019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.278709</td>\n",
       "      <td>-78.623847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.124485</td>\n",
       "      <td>-78.605621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>-0.113891</td>\n",
       "      <td>-78.577449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>-0.848796</td>\n",
       "      <td>0.136726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  location_number location_type    latitude  longitude\n",
       "0     Z59FTQD                0         Other  126.032278  -9.106019\n",
       "1     0JP29SK                0          Home    0.278709 -78.623847\n",
       "2     0JP29SK                1          Home    0.124485 -78.605621\n",
       "3     0JP29SK                2         Other   -0.113891 -78.577449\n",
       "4     0JP29SK                3         Other   -0.848796   0.136726"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_test = test_locations\n",
    "users_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant utilise l'algorithme des plus proches voisins pour trouver, parmi un groupe d'utilisateurs d'entraînement, l'utilisateur le plus proche de chaque utilisateur de test en fonction de leurs coordonnées géographiques (latitude et longitude). Tout d'abord, les données sont préparées en supprimant les utilisateurs dont les coordonnées sont manquantes. Ensuite, les coordonnées sont converties en radians pour faciliter les calculs. L'algorithme des plus proches voisins est ensuite appliqué en utilisant les données d'entraînement pour trouver le voisin le plus proche de chaque utilisateur de test. Les informations de l'utilisateur le plus proche, telles que son identifiant et le numéro de son emplacement, sont ensuite associées à chaque utilisateur de test. Cela permet de déterminer les utilisateurs les plus similaires en termes de localisation géographique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "users = users.dropna(subset=['latitude', 'longitude'])\n",
    "users_test = users_test.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Convert latitude and longitude to radians\n",
    "users['latitude'] = np.radians(users['latitude'])\n",
    "users['longitude'] = np.radians(users['longitude'])\n",
    "users_test['latitude'] = np.radians(users_test['latitude'])\n",
    "users_test['longitude'] = np.radians(users_test['longitude'])\n",
    "\n",
    "# Prepare data for NearestNeighbors\n",
    "X_train = users[['latitude', 'longitude']]\n",
    "X_test = users_test[['latitude', 'longitude']]\n",
    "\n",
    "# Fit NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=1, algorithm='ball_tree', metric='haversine')\n",
    "nn.fit(X_train)\n",
    "\n",
    "# Find closest users\n",
    "distances, indices = nn.kneighbors(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Replace each test user with the closest user from the training set\n",
    "users_test['closest_user'] = [users.iloc[index[0]]['customer_id'] for index in indices]\n",
    "users_test['location_number_2'] = [users.iloc[index[0]]['location_number'] for index in indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>location_number</th>\n",
       "      <th>location_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>closest_user</th>\n",
       "      <th>location_number_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z59FTQD</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.199678</td>\n",
       "      <td>-0.158930</td>\n",
       "      <td>OV01MGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>-1.372245</td>\n",
       "      <td>S1SJNJX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>-1.371927</td>\n",
       "      <td>EKBKVS9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>-1.371435</td>\n",
       "      <td>C5JX00T</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0JP29SK</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>-0.014814</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>IK3W1ZZ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  location_number location_type  latitude  longitude  \\\n",
       "0     Z59FTQD                0         Other  2.199678  -0.158930   \n",
       "1     0JP29SK                0          Home  0.004864  -1.372245   \n",
       "2     0JP29SK                1          Home  0.002173  -1.371927   \n",
       "3     0JP29SK                2         Other -0.001988  -1.371435   \n",
       "4     0JP29SK                3         Other -0.014814   0.002386   \n",
       "\n",
       "  closest_user  location_number_2  \n",
       "0      OV01MGG                  0  \n",
       "1      S1SJNJX                  1  \n",
       "2      EKBKVS9                  0  \n",
       "3      C5JX00T                  0  \n",
       "4      IK3W1ZZ                  2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Le code suivant réalise une opération appelée \"produit cartésien\" entre les données des utilisateurs de test et les informations sur les vendeurs. Cela signifie qu'il crée toutes les combinaisons possibles entre chaque utilisateur de test et chaque vendeur. Ensuite, il crée deux nouvelles colonnes dans le DataFrame résultant. La première colonne combine l'identifiant de l'utilisateur le plus proche, le numéro de son emplacement et l'identifiant du vendeur pour représenter une paire utilisateur-vendeur. La deuxième colonne combine l'identifiant du client réel, le numéro de son emplacement et l'identifiant du vendeur. Enfin, seules les colonnes nécessaires sont conservées dans le DataFrame final, qui contient les informations pertinentes pour l'analyse ultérieure.\n",
    "\n",
    "C'est sur ce DataFrame que l'on va tester l'algorithme ALS à la fin et obtenir les recommendations pour les clients du dataset de test.\n",
    "\n",
    "En résumé on va donner à chaque client du dataset test, les recommandations pour les clients du dataset train étant les plus proches géographiquement que l'on obtiendra grâce à ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_test['key'] = 1\n",
    "vendors['key'] = 1\n",
    "\n",
    "# Perform the Cartesian product (cross join)\n",
    "test_df = pd.merge(users_test, vendors, on='key').drop('key', axis=1)\n",
    "\n",
    "# Create the new column\n",
    "test_df['CID X LOC_NUM X VENDOR'] = test_df['closest_user'].astype(str) + ' X ' + test_df['location_number_2'].astype(str) + ' X ' + test_df['vendor_id'].astype(str)\n",
    "test_df['real_CID X LOC_NUM X VENDOR'] = test_df['customer_id'].astype(str) + ' X ' + test_df['location_number'].astype(str) + ' X ' + test_df['vendor_id'].astype(str)\n",
    "\n",
    "# Keep only the necessary columns\n",
    "test_df = test_df[['CID X LOC_NUM X VENDOR', 'vendor_id','real_CID X LOC_NUM X VENDOR']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction haversine dans le code permet de calculer la distance en kilomètres entre deux points géographiques spécifiés par leurs coordonnées de latitude et de longitude. Elle utilise la formule de la distance haversine, qui prend en compte la courbure de la Terre pour obtenir une mesure plus précise. En convertissant les coordonnées de degrés décimaux en radians, la fonction calcule la différence de latitude et de longitude entre les deux points. En utilisant ces différences dans la formule haversine, elle détermine la distance angulaire centrale entre les deux points. En multipliant cette distance par le rayon de la Terre, la fonction renvoie la distance en kilomètres. Cela permet de calculer facilement la distance géographique entre deux points donnés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code combine les données des DataFrames orders, users, et vendors en fusionnant les colonnes d'identifiant correspondantes. Cela crée un nouveau DataFrame appelé df qui contient les informations combinées des commandes, des clients, et des vendeurs. Ensuite, le code utilise la fonction haversine pour calculer la distance géographique entre chaque paire client-vendeur en utilisant les coordonnées de longitude et de latitude. Cette distance est ajoutée en tant que nouvelle colonne 'distance' dans le DataFrame df. Ainsi, le DataFrame df contient maintenant les données de commande, les informations des clients, les informations des vendeurs, et la distance géographique pour chaque commande, ce qui sera utile pour les analyses futures.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the orders and customers dataframes\n",
    "df = pd.merge(orders, users, on='customer_id')\n",
    "\n",
    "# Merge the resultant dataframe with the vendors dataframe\n",
    "df = pd.merge(df, vendors, on='vendor_id')\n",
    "df['distance'] = df.apply(lambda row: haversine(row['longitude_x'], row['latitude_x'], row['longitude_y'], row['latitude_y']), axis=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code regroupe les données du DataFrame df par client et vendeur, puis calcule plusieurs métriques pour chaque groupe, telles que le nombre de commandes répétées, la note moyenne du vendeur, la note moyenne du livreur, le temps moyen de préparation et la distance moyenne. Ensuite, les valeurs de ces métriques sont normalisées pour les ramener à une échelle de 0 à 1. Des poids sont ensuite assignés à chaque métrique pour refléter leur importance relative. La note finale est calculée en combinant les métriques pondérées. Le DataFrame est ensuite réorganisé pour aplatir la structure multi-index et fusionné avec le DataFrame initial pour obtenir un DataFrame final qui contient les notes des clients pour chaque vendeur. Cela permet de classer les vendeurs en fonction de leur performance globale, basée sur les métriques spécifiées.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by customer and vendor to calculate the metrics\n",
    "grouped = df.groupby(['customer_id', 'vendor_id']).agg({\n",
    "    'akeed_order_id': 'count',  # Reorder count\n",
    "    'vendor_rating_x': 'mean',  # Average vendor rating\n",
    "    'driver_rating': 'mean',  # Average driver rating\n",
    "    'preparationtime': 'mean',  # Average preparation time\n",
    "    'distance': 'mean',  # Average distance\n",
    "}).rename(columns={'akeed_order_id': 'reorders'})\n",
    "\n",
    "# Normalize columns to be between 0 and 1\n",
    "grouped = (grouped - grouped.min()) / (grouped.max() - grouped.min())\n",
    "\n",
    "# Define the weights for the features\n",
    "weights = {\n",
    "    'reorders': 0.1,\n",
    "    'vendor_rating_x': 0.8,\n",
    "    'driver_rating': 0.1,\n",
    "    'preparationtime': -0.2,  # Negative because shorter is better\n",
    "    'distance': -0.8,  # Negative because shorter is better\n",
    "}\n",
    "\n",
    "# Calculate rating as a weighted sum of features\n",
    "grouped['rating'] = np.dot(grouped[weights.keys()], list(weights.values()))\n",
    "\n",
    "# Flatten the multi-index DataFrame\n",
    "grouped.reset_index(inplace=True)\n",
    "\n",
    "# Merge back with original DataFrame\n",
    "df = pd.merge(df, grouped[['customer_id', 'vendor_id', 'rating']], on=['customer_id', 'vendor_id'], how='left')\n",
    "final_df = df[['CID X LOC_NUM X VENDOR', 'vendor_id', 'rating']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID X LOC_NUM X VENDOR</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92PEE24 X 0 X 105</td>\n",
       "      <td>105</td>\n",
       "      <td>0.249295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92PEE24 X 0 X 105</td>\n",
       "      <td>105</td>\n",
       "      <td>0.249295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92PEE24 X 0 X 105</td>\n",
       "      <td>105</td>\n",
       "      <td>0.249295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92PEE24 X 0 X 105</td>\n",
       "      <td>105</td>\n",
       "      <td>0.249295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92PEE24 X 0 X 105</td>\n",
       "      <td>105</td>\n",
       "      <td>0.249295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395594</th>\n",
       "      <td>6PY2OK5 X 0 X 907</td>\n",
       "      <td>907</td>\n",
       "      <td>0.158494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395595</th>\n",
       "      <td>UPNI9BV X 0 X 907</td>\n",
       "      <td>907</td>\n",
       "      <td>0.158710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395596</th>\n",
       "      <td>U6PTUT5 X 0 X 907</td>\n",
       "      <td>907</td>\n",
       "      <td>0.745027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395597</th>\n",
       "      <td>MSEGQHZ X 0 X 907</td>\n",
       "      <td>907</td>\n",
       "      <td>0.158588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395598</th>\n",
       "      <td>ND4PIJL X 0 X 907</td>\n",
       "      <td>907</td>\n",
       "      <td>0.158591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395599 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CID X LOC_NUM X VENDOR  vendor_id    rating\n",
       "0           92PEE24 X 0 X 105        105  0.249295\n",
       "1           92PEE24 X 0 X 105        105  0.249295\n",
       "2           92PEE24 X 0 X 105        105  0.249295\n",
       "3           92PEE24 X 0 X 105        105  0.249295\n",
       "4           92PEE24 X 0 X 105        105  0.249295\n",
       "...                       ...        ...       ...\n",
       "395594      6PY2OK5 X 0 X 907        907  0.158494\n",
       "395595      UPNI9BV X 0 X 907        907  0.158710\n",
       "395596      U6PTUT5 X 0 X 907        907  0.745027\n",
       "395597      MSEGQHZ X 0 X 907        907  0.158588\n",
       "395598      ND4PIJL X 0 X 907        907  0.158591\n",
       "\n",
       "[395599 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de Spark pour le traitement de données massives et la conversion de DataFrames pandas en DataFrames Spark\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/17 18:20:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('ALS') \\\n",
    "    .config('spark.driver.memory', '4g') \\\n",
    "    .config('spark.executor.memory', '4g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Convert the pandas DataFrame to a Spark DataFrame\n",
    "spark_df = spark.createDataFrame(final_df)\n",
    "spark_test_df = spark.createDataFrame(test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe de training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:08 WARN TaskSetManager: Stage 0 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:09 WARN TaskSetManager: Stage 3 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+------------------+---------------+----------------------------+\n",
      "|CID X LOC_NUM X VENDOR|vendor_id|            rating|vendor_id_index|CID X LOC_NUM X VENDOR_index|\n",
      "+----------------------+---------+------------------+---------------+----------------------------+\n",
      "|     92PEE24 X 0 X 105|      105|0.2492953247882893|            2.0|                     14664.0|\n",
      "|     92PEE24 X 0 X 105|      105|0.2492953247882893|            2.0|                     14664.0|\n",
      "|     92PEE24 X 0 X 105|      105|0.2492953247882893|            2.0|                     14664.0|\n",
      "|     92PEE24 X 0 X 105|      105|0.2492953247882893|            2.0|                     14664.0|\n",
      "|     92PEE24 X 0 X 105|      105|0.2492953247882893|            2.0|                     14664.0|\n",
      "|     92PEE24 X 0 X 105|      105|0.2492953247882893|            2.0|                     14664.0|\n",
      "|     92PEE24 X 1 X 105|      105|0.2492953247882893|            2.0|                     48950.0|\n",
      "|     92PEE24 X 1 X 105|      105|0.2492953247882893|            2.0|                     48950.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "|     I9DNSMJ X 0 X 105|      105|0.2518450956875943|            2.0|                       815.0|\n",
      "+----------------------+---------+------------------+---------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:10 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:10 WARN TaskSetManager: Stage 6 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "indexer = [\n",
    "    StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
    "    for column in list(set(spark_df.columns) - set([\"rating\"]))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "transformed = pipeline.fit(spark_df).transform(spark_df)\n",
    "transformed.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:10 WARN TaskSetManager: Stage 7 contains a task of very large size (8974 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:11 WARN TaskSetManager: Stage 10 contains a task of very large size (8974 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:18 WARN DAGScheduler: Broadcasting large task binary with size 49.5 MiB\n",
      "23/05/17 18:21:18 WARN TaskSetManager: Stage 13 contains a task of very large size (8974 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+---------------------------+---------------+----------------------------+\n",
      "|CID X LOC_NUM X VENDOR|vendor_id|real_CID X LOC_NUM X VENDOR|vendor_id_index|CID X LOC_NUM X VENDOR_index|\n",
      "+----------------------+---------+---------------------------+---------------+----------------------------+\n",
      "|       OV01MGG X 0 X 4|        4|            Z59FTQD X 0 X 4|           59.0|                   1027259.0|\n",
      "|      OV01MGG X 0 X 13|       13|           Z59FTQD X 0 X 13|            6.0|                   1027206.0|\n",
      "|      OV01MGG X 0 X 20|       20|           Z59FTQD X 0 X 20|           27.0|                   1027227.0|\n",
      "|      OV01MGG X 0 X 23|       23|           Z59FTQD X 0 X 23|           34.0|                   1027234.0|\n",
      "|      OV01MGG X 0 X 28|       28|           Z59FTQD X 0 X 28|           43.0|                   1027243.0|\n",
      "|      OV01MGG X 0 X 33|       33|           Z59FTQD X 0 X 33|           54.0|                   1027254.0|\n",
      "|      OV01MGG X 0 X 43|       43|           Z59FTQD X 0 X 43|           62.0|                   1027262.0|\n",
      "|      OV01MGG X 0 X 44|       44|           Z59FTQD X 0 X 44|           63.0|                   1027263.0|\n",
      "|      OV01MGG X 0 X 55|       55|           Z59FTQD X 0 X 55|           67.0|                   1027267.0|\n",
      "|      OV01MGG X 0 X 66|       66|           Z59FTQD X 0 X 66|           74.0|                   1027274.0|\n",
      "|      OV01MGG X 0 X 67|       67|           Z59FTQD X 0 X 67|           75.0|                   1027275.0|\n",
      "|      OV01MGG X 0 X 75|       75|           Z59FTQD X 0 X 75|           79.0|                   1027279.0|\n",
      "|      OV01MGG X 0 X 76|       76|           Z59FTQD X 0 X 76|           80.0|                   1027280.0|\n",
      "|      OV01MGG X 0 X 78|       78|           Z59FTQD X 0 X 78|           81.0|                   1027281.0|\n",
      "|      OV01MGG X 0 X 79|       79|           Z59FTQD X 0 X 79|           82.0|                   1027282.0|\n",
      "|      OV01MGG X 0 X 81|       81|           Z59FTQD X 0 X 81|           83.0|                   1027283.0|\n",
      "|      OV01MGG X 0 X 82|       82|           Z59FTQD X 0 X 82|           84.0|                   1027284.0|\n",
      "|      OV01MGG X 0 X 83|       83|           Z59FTQD X 0 X 83|           85.0|                   1027285.0|\n",
      "|      OV01MGG X 0 X 84|       84|           Z59FTQD X 0 X 84|           86.0|                   1027286.0|\n",
      "|      OV01MGG X 0 X 85|       85|           Z59FTQD X 0 X 85|           92.0|                   1027292.0|\n",
      "+----------------------+---------+---------------------------+---------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:22 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 13 (TID 37): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexer = [\n",
    "    StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
    "    for column in list(set(spark_test_df.columns) - set([\"rating\", \"real_CID X LOC_NUM X VENDOR\"]))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "transformed_test = pipeline.fit(spark_test_df).transform(spark_test_df)\n",
    "transformed_test.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce code, nous utilisons la bibliothèque pyspark pour entraîner un modèle ALS (Alternating Least Squares) à des fins de recommandation personnalisée. Tout d'abord, les données sont divisées en ensembles d'entraînement et de test. L'ensemble d'entraînement représente 80% des données, tandis que l'ensemble de test représente 20%. Ensuite,un modèle ALS est créé avec des paramètres spécifiés, puis ajusté sur l'ensemble d'entraînement pour générer un modèle prêt à être utilisé pour les recommandations personnalisées.\n",
    "\n",
    " Une fois l'entraînement terminé, nous obtenons un modèle prêt à être utilisé pour générer des recommandations personnalisées basées sur les notes fournies dans le DataFrame df_final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:23 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:23 WARN TaskSetManager: Stage 14 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:23 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:23 WARN TaskSetManager: Stage 15 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:24 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:24 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:24 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:25 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:25 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:25 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/17 18:21:25 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "23/05/17 18:21:25 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:26 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:26 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:27 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:27 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:27 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:27 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:27 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:28 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:28 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:28 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:28 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:29 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:29 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:29 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:29 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:30 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:30 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:30 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:30 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:30 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:31 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:31 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:31 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:31 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:31 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:32 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:32 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:32 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:32 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:33 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(training, test) = transformed.randomSplit([0.8, 0.2], seed=42)\n",
    "als = ALS(\n",
    "    maxIter=15,\n",
    "    regParam=0.01,\n",
    "    rank=50,\n",
    "    userCol=\"CID X LOC_NUM X VENDOR_index\",\n",
    "    itemCol=\"vendor_id_index\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True,\n",
    ")\n",
    "\n",
    "\n",
    "model = als.fit(training)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code utilise le modèle entraîné pour faire des prédictions sur l'ensemble de test. Ensuite, il évalue les performances du modèle en calculant le RMSE (erreur quadratique moyenne) entre les prédictions et les valeurs réelles. Enfin, il affiche le RMSE et les prédictions pour évaluer la précision du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:33 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:33 WARN TaskSetManager: Stage 88 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:33 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:33 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:34 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:34 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.04936848481971961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:35 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:35 WARN TaskSetManager: Stage 199 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:35 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:35 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:36 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+-------------------+---------------+----------------------------+----------+\n",
      "|CID X LOC_NUM X VENDOR|vendor_id|             rating|vendor_id_index|CID X LOC_NUM X VENDOR_index|prediction|\n",
      "+----------------------+---------+-------------------+---------------+----------------------------+----------+\n",
      "|     17Q7881 X 1 X 221|      221| 0.2002660426264149|           31.0|                       587.0|0.19181734|\n",
      "|     17Q7881 X 1 X 221|      221| 0.2002660426264149|           31.0|                       587.0|0.19181734|\n",
      "|     17Q7881 X 1 X 221|      221| 0.2002660426264149|           31.0|                       587.0|0.19181734|\n",
      "|     17Q7881 X 1 X 221|      221| 0.2002660426264149|           31.0|                       587.0|0.19181734|\n",
      "|     17Q7881 X 1 X 221|      221| 0.2002660426264149|           31.0|                       587.0|0.19181734|\n",
      "|     17Q7881 X 1 X 221|      221| 0.2002660426264149|           31.0|                       587.0|0.19181734|\n",
      "|     17Q7881 X 1 X 221|      221| 0.2002660426264149|           31.0|                       587.0|0.19181734|\n",
      "|     17Q7881 X 1 X 221|      221| 0.2002660426264149|           31.0|                       587.0|0.19181734|\n",
      "|     T2PK2DJ X 1 X 221|      221| 0.2506948623621184|           31.0|                       853.0| 0.2401187|\n",
      "|     T2PK2DJ X 1 X 221|      221| 0.2506948623621184|           31.0|                       853.0| 0.2401187|\n",
      "|     T2PK2DJ X 1 X 221|      221| 0.2506948623621184|           31.0|                       853.0| 0.2401187|\n",
      "|     T2PK2DJ X 1 X 221|      221| 0.2506948623621184|           31.0|                       853.0| 0.2401187|\n",
      "|     T2PK2DJ X 1 X 221|      221| 0.2506948623621184|           31.0|                       853.0| 0.2401187|\n",
      "|     T2PK2DJ X 1 X 221|      221| 0.2506948623621184|           31.0|                       853.0| 0.2401187|\n",
      "|     BUIAFFT X 2 X 221|      221|0.17744217407668725|           31.0|                      1148.0|0.16995634|\n",
      "|     BUIAFFT X 2 X 221|      221|0.17744217407668725|           31.0|                      1148.0|0.16995634|\n",
      "|     BUIAFFT X 2 X 221|      221|0.17744217407668725|           31.0|                      1148.0|0.16995634|\n",
      "|     BUIAFFT X 2 X 221|      221|0.17744217407668725|           31.0|                      1148.0|0.16995634|\n",
      "|     BUIAFFT X 2 X 221|      221|0.17744217407668725|           31.0|                      1148.0|0.16995634|\n",
      "|     BUIAFFT X 2 X 221|      221|0.17744217407668725|           31.0|                      1148.0|0.16995634|\n",
      "+----------------------+---------+-------------------+---------------+----------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "# Instantiate the evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error = {rmse}\")\n",
    "\n",
    "# You may also want to take a look at the predictions DataFrame\n",
    "predictions.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code utilise le 90e percentile des prédictions et des valeurs réelles pour définir un seuil. Ensuite, il transforme les prédictions et les valeurs réelles en valeurs binaires en les comparant avec ce seuil. Le DataFrame predictions contient désormais des prédictions et des valeurs binaires dans les colonnes correspondantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:36 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:36 WARN TaskSetManager: Stage 310 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:36 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:36 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:37 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:38 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:38 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:38 WARN TaskSetManager: Stage 421 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:38 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:38 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:39 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:39 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:39 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:39 WARN TaskSetManager: Stage 532 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:39 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:39 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "[Stage 566:========>       (5 + 5) / 10][Stage 567:>               (0 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+------+---------------+----------------------------+----------+\n",
      "|CID X LOC_NUM X VENDOR|vendor_id|rating|vendor_id_index|CID X LOC_NUM X VENDOR_index|prediction|\n",
      "+----------------------+---------+------+---------------+----------------------------+----------+\n",
      "|     17Q7881 X 1 X 221|      221|   0.0|           31.0|                       587.0|       0.0|\n",
      "|     17Q7881 X 1 X 221|      221|   0.0|           31.0|                       587.0|       0.0|\n",
      "|     17Q7881 X 1 X 221|      221|   0.0|           31.0|                       587.0|       0.0|\n",
      "|     17Q7881 X 1 X 221|      221|   0.0|           31.0|                       587.0|       0.0|\n",
      "|     17Q7881 X 1 X 221|      221|   0.0|           31.0|                       587.0|       0.0|\n",
      "|     17Q7881 X 1 X 221|      221|   0.0|           31.0|                       587.0|       0.0|\n",
      "|     17Q7881 X 1 X 221|      221|   0.0|           31.0|                       587.0|       0.0|\n",
      "|     17Q7881 X 1 X 221|      221|   0.0|           31.0|                       587.0|       0.0|\n",
      "|     T2PK2DJ X 1 X 221|      221|   0.0|           31.0|                       853.0|       0.0|\n",
      "|     T2PK2DJ X 1 X 221|      221|   0.0|           31.0|                       853.0|       0.0|\n",
      "|     T2PK2DJ X 1 X 221|      221|   0.0|           31.0|                       853.0|       0.0|\n",
      "|     T2PK2DJ X 1 X 221|      221|   0.0|           31.0|                       853.0|       0.0|\n",
      "|     T2PK2DJ X 1 X 221|      221|   0.0|           31.0|                       853.0|       0.0|\n",
      "|     T2PK2DJ X 1 X 221|      221|   0.0|           31.0|                       853.0|       0.0|\n",
      "|     BUIAFFT X 2 X 221|      221|   0.0|           31.0|                      1148.0|       0.0|\n",
      "|     BUIAFFT X 2 X 221|      221|   0.0|           31.0|                      1148.0|       0.0|\n",
      "|     BUIAFFT X 2 X 221|      221|   0.0|           31.0|                      1148.0|       0.0|\n",
      "|     BUIAFFT X 2 X 221|      221|   0.0|           31.0|                      1148.0|       0.0|\n",
      "|     BUIAFFT X 2 X 221|      221|   0.0|           31.0|                      1148.0|       0.0|\n",
      "|     BUIAFFT X 2 X 221|      221|   0.0|           31.0|                      1148.0|       0.0|\n",
      "+----------------------+---------+------+---------------+----------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:40 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Set the threshold to be the 90% of predicted ratings\n",
    "threshold = predictions.approxQuantile(\"prediction\", [0.9], 0)[0]\n",
    "threshold = predictions.approxQuantile(\"rating\", [0.9], 0)[0]\n",
    "\n",
    "# If the predicted rating is greater than the threshold, predict 1, else 0\n",
    "predictions = predictions.withColumn(\"prediction\", (col(\"prediction\") > threshold).cast(\"double\"))\n",
    "predictions = predictions.withColumn(\"rating\", (col(\"rating\") > threshold).cast(\"double\"))\n",
    "\n",
    "# Now \"prediction\" column contains binary values\n",
    "predictions.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code évalue les performances du modèle de classification binaire en calculant le score F1. Ce score mesure la précision globale du modèle en prenant en compte à la fois la précision et le rappel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:41 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:41 WARN TaskSetManager: Stage 643 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:41 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:41 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:41 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:42 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.974568365668147\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "predictions = predictions.withColumn(\"prediction\", col(\"prediction\").cast(\"double\"))\n",
    "\n",
    "# Create an evaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"rating\", metricName=\"areaUnderPR\")\n",
    "\n",
    "# Compute F1 score\n",
    "f1 = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenant on refait ca en utilisant les données de test (contenues dans transform_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On commence par l'entrainer sur toutes les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:42 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:42 WARN TaskSetManager: Stage 911 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:42 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:42 WARN TaskSetManager: Stage 912 contains a task of very large size (1038 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:43 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:43 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:44 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:44 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:44 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:44 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:45 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:45 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:45 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:45 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:45 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:46 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:46 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:46 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:46 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:47 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:47 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:47 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:47 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:47 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:48 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:48 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:48 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:48 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:48 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:49 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n"
     ]
    }
   ],
   "source": [
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.01,\n",
    "    rank=50,\n",
    "    userCol=\"CID X LOC_NUM X VENDOR_index\",\n",
    "    itemCol=\"vendor_id_index\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True,\n",
    ")\n",
    "\n",
    "\n",
    "model = als.fit(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:21:50 WARN DAGScheduler: Broadcasting large task binary with size 49.5 MiB\n",
      "23/05/17 18:21:50 WARN TaskSetManager: Stage 965 contains a task of very large size (8974 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:21:50 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:21:50 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:21:57 WARN DAGScheduler: Broadcasting large task binary with size 52.5 MiB\n",
      "23/05/17 18:22:02 WARN DAGScheduler: Broadcasting large task binary with size 52.5 MiB\n",
      "23/05/17 18:22:07 WARN DAGScheduler: Broadcasting large task binary with size 52.5 MiB\n",
      "23/05/17 18:22:10 WARN DAGScheduler: Broadcasting large task binary with size 49.5 MiB\n",
      "23/05/17 18:22:10 WARN TaskSetManager: Stage 1047 contains a task of very large size (8974 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:22:10 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:22:11 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:22:16 WARN PythonRunner: Detected deadlock while completing task 5.0 in stage 1047 (TID 975): Attempting to kill Python Worker\n",
      "23/05/17 18:22:16 WARN PythonRunner: Detected deadlock while completing task 3.0 in stage 1047 (TID 973): Attempting to kill Python Worker\n",
      "23/05/17 18:22:16 WARN PythonRunner: Detected deadlock while completing task 4.0 in stage 1047 (TID 974): Attempting to kill Python Worker\n",
      "23/05/17 18:22:16 WARN PythonRunner: Detected deadlock while completing task 7.0 in stage 1047 (TID 977): Attempting to kill Python Worker\n",
      "23/05/17 18:22:16 WARN PythonRunner: Detected deadlock while completing task 1.0 in stage 1047 (TID 971): Attempting to kill Python Worker\n",
      "23/05/17 18:22:16 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 1047 (TID 970): Attempting to kill Python Worker\n",
      "23/05/17 18:22:16 WARN PythonRunner: Detected deadlock while completing task 2.0 in stage 1047 (TID 972): Attempting to kill Python Worker\n",
      "23/05/17 18:22:16 WARN PythonRunner: Detected deadlock while completing task 6.0 in stage 1047 (TID 976): Attempting to kill Python Worker\n",
      "23/05/17 18:22:18 WARN DAGScheduler: Broadcasting large task binary with size 52.5 MiB\n",
      "[Stage 1098:>               (0 + 8) / 8][Stage 1100:>               (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+---------------------------+---------------+----------------------------+----------+\n",
      "|CID X LOC_NUM X VENDOR|vendor_id|real_CID X LOC_NUM X VENDOR|vendor_id_index|CID X LOC_NUM X VENDOR_index|prediction|\n",
      "+----------------------+---------+---------------------------+---------------+----------------------------+----------+\n",
      "|     JO0ZUCM X 0 X 681|      681|          ZL9OED7 X 0 X 681|           78.0|                    150878.0|         0|\n",
      "|     NEC5RKF X 0 X 681|      681|          QRW34UN X 0 X 681|           78.0|                    173678.0|         0|\n",
      "|      5JY8STQ X 0 X 23|       23|           ANRC0AL X 1 X 23|           34.0|                    421334.0|         0|\n",
      "|      OV01MGG X 0 X 78|       78|           Z59FTQD X 0 X 78|           81.0|                   1027281.0|         0|\n",
      "|      OV01MGG X 0 X 20|       20|           Z59FTQD X 0 X 20|           27.0|                   1027227.0|         0|\n",
      "|     NEC5RKF X 0 X 849|      849|          QRW34UN X 0 X 849|           91.0|                    173691.0|         0|\n",
      "|      OV01MGG X 0 X 86|       86|           Z59FTQD X 0 X 86|           96.0|                   1027296.0|         0|\n",
      "|     NEC5RKF X 0 X 843|      843|          QRW34UN X 0 X 843|           88.0|                    173688.0|         0|\n",
      "|     JO0ZUCM X 0 X 356|      356|          ZL9OED7 X 0 X 356|           55.0|                    150855.0|         0|\n",
      "|      5JY8STQ X 0 X 44|       44|           ANRC0AL X 1 X 44|           63.0|                    421363.0|         0|\n",
      "|     NEC5RKF X 0 X 679|      679|          QRW34UN X 0 X 679|           77.0|                    173677.0|         0|\n",
      "|      OV01MGG X 0 X 76|       76|           Z59FTQD X 0 X 76|           80.0|                   1027280.0|         0|\n",
      "|     JO0ZUCM X 0 X 577|      577|          ZL9OED7 X 0 X 577|           70.0|                    150870.0|         0|\n",
      "|     NEC5RKF X 0 X 577|      577|          QRW34UN X 0 X 577|           70.0|                    173670.0|         0|\n",
      "|      5JY8STQ X 0 X 43|       43|           ANRC0AL X 1 X 43|           62.0|                    421362.0|         0|\n",
      "|      OV01MGG X 0 X 43|       43|           Z59FTQD X 0 X 43|           62.0|                   1027262.0|         0|\n",
      "|     WQ9CCON X 1 X 858|      858|          ANRC0AL X 0 X 858|           95.0|                     37195.0|         1|\n",
      "|     5PU6VVK X 2 X 858|      858|          00ICGWM X 1 X 858|           95.0|                    427395.0|         0|\n",
      "|     JO0ZUCM X 0 X 573|      573|          ZL9OED7 X 0 X 573|           68.0|                    150868.0|         0|\n",
      "|     GPISF6F X 1 X 573|      573|          TYPW7MB X 0 X 573|           68.0|                    767568.0|         0|\n",
      "+----------------------+---------+---------------------------+---------------+----------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.setColdStartStrategy(\"nan\")\n",
    "predictions = model.transform(transformed_test)\n",
    "predictions = predictions.na.fill({'prediction': 0})\n",
    "\n",
    "# Set the threshold to be the 90% of predicted ratings\n",
    "threshold = predictions.approxQuantile(\"prediction\", [0.9], 0)[0]\n",
    "# If the predicted rating is greater than the threshold, predict 1, else 0\n",
    "predictions = predictions.withColumn(\"prediction\", (col(\"prediction\") > threshold).cast(\"int\"))\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:22:22 WARN DAGScheduler: Broadcasting large task binary with size 49.5 MiB\n",
      "23/05/17 18:22:22 WARN TaskSetManager: Stage 1128 contains a task of very large size (8974 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:22:22 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:22:22 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:22:27 WARN DAGScheduler: Broadcasting large task binary with size 52.5 MiB\n",
      "23/05/17 18:22:32 WARN DAGScheduler: Broadcasting large task binary with size 49.5 MiB\n",
      "23/05/17 18:22:32 WARN TaskSetManager: Stage 1209 contains a task of very large size (8974 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:22:32 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:22:32 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:22:40 WARN DAGScheduler: Broadcasting large task binary with size 52.5 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of 1s to 0s is: 0.11110963435721112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "num_ones = predictions.filter(predictions.prediction == 1).count()\n",
    "num_zeros = predictions.filter(predictions.prediction == 0).count()\n",
    "\n",
    "# calculate the ratio\n",
    "if num_zeros != 0:\n",
    "    ratio = num_ones / num_zeros\n",
    "else:\n",
    "    ratio = 'Undefined' # to avoid division by zero\n",
    "\n",
    "print('The ratio of 1s to 0s is:', ratio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code prépare les résultats des prédictions pour la soumission en sélectionnant les colonnes pertinentes, en les renommant et en enregistrant le résultat au format CSV dans un fichier nommé \"submission.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/17 18:22:46 WARN DAGScheduler: Broadcasting large task binary with size 49.5 MiB\n",
      "23/05/17 18:22:46 WARN TaskSetManager: Stage 1318 contains a task of very large size (8974 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/05/17 18:22:46 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/05/17 18:22:46 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/05/17 18:22:52 WARN DAGScheduler: Broadcasting large task binary with size 52.7 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "submission = predictions.select(\"real_CID X LOC_NUM X VENDOR\", \"prediction\")\n",
    "submission = submission.withColumnRenamed(\"real_CID X LOC_NUM X VENDOR\", \"CID X LOC_NUM X VENDOR\")\n",
    "submission = submission.withColumnRenamed(\"prediction\", \"target\")\n",
    "\n",
    "submission.coalesce(1).write.format(\"csv\").option(\"header\",\"true\").save(\"submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
